batch_size: 128
test_batch_size: 1000
epochs: 50
lr: 0.01
momentum: 0.5
no_cuda: False
seed: 1
log_interval: 10
optim: sgd
dmom: 0.5
low_theta: 1.e-5
high_theta: 1.e5
arch: mlp
workers: 2
weight_decay: 5.e-4
dmom_interval: 1
dmom_temp: 0
alpha: normg
sampler: False
train_accuracy: True
alpha_norm: none
sampler_weight: alpha
wmomentum: False
log_image: True
lr_decay_epoch: 30
norm_temp: 1
sampler_alpha_th: 0
sampler_alpha_perc: 0
